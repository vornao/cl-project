{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Model created and moved to cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0614983425301034, Accuracy: 0.635, Val Loss: 0.5571795701980591, Val Acc: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.40281935161715593, Accuracy: 0.862, Val Loss: 0.366889625787735, Val Acc: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.27232630198871904, Accuracy: 0.904, Val Loss: 0.32728254795074463, Val Acc: 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import MNISTConvNet, MNISTConvNetTrainer, get_mnist_dataloader\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "train, val, test = get_mnist_dataloader(128)\n",
    "# sample 1000 images from the training set\n",
    "train = DataLoader(Subset(train.dataset, range(1000)))\n",
    "\n",
    "# print some sample images from the training set with matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(2, 5, figsize=(12, 3))\n",
    "# for i, ax in enumerate(axs.flat):\n",
    "#     ax.imshow(train.dataset[i][0].squeeze(), cmap='gray')\n",
    "#     ax.set_title(f'Label: {train.dataset[i][1]}')\n",
    "\n",
    "model   = MNISTConvNet()\n",
    "trainer = MNISTConvNetTrainer(model, train, val, device='cpu')\n",
    "\n",
    "trainer.train(num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x13eb369f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training client 0\n",
      "Local Epoch 1, Loss: 0.1268272379057857, Accuracy: 0.961, client: 0, total: 1000\n",
      "Local Epoch 2, Loss: 0.10452932583852291, Accuracy: 0.964, client: 0, total: 1000\n",
      "Local Epoch 3, Loss: 0.09242231046153375, Accuracy: 0.97, client: 0, total: 1000\n",
      "Local Epoch 4, Loss: 0.08285702297370963, Accuracy: 0.976, client: 0, total: 1000\n",
      "Local Epoch 5, Loss: 0.07500874344255715, Accuracy: 0.975, client: 0, total: 1000\n",
      "Training client 1\n",
      "Local Epoch 1, Loss: 0.1268272379057857, Accuracy: 0.961, client: 1, total: 1000\n",
      "Local Epoch 2, Loss: 0.10452932583852291, Accuracy: 0.964, client: 1, total: 1000\n",
      "Local Epoch 3, Loss: 0.09242231046153375, Accuracy: 0.97, client: 1, total: 1000\n",
      "Local Epoch 4, Loss: 0.08285702297370963, Accuracy: 0.976, client: 1, total: 1000\n",
      "Local Epoch 5, Loss: 0.07500874344255715, Accuracy: 0.975, client: 1, total: 1000\n",
      "Aggregating 2 local states\n",
      "Round 0, Test Loss: 0.28992077708244324, Test Acc: 0.9197\n",
      "Training client 0\n",
      "Local Epoch 1, Loss: 0.06762130718327689, Accuracy: 0.977, client: 0, total: 1000\n",
      "Local Epoch 2, Loss: 0.0610035588815347, Accuracy: 0.984, client: 0, total: 1000\n",
      "Local Epoch 3, Loss: 0.05521718112655039, Accuracy: 0.988, client: 0, total: 1000\n",
      "Local Epoch 4, Loss: 0.049247740970864415, Accuracy: 0.989, client: 0, total: 1000\n",
      "Local Epoch 5, Loss: 0.04433827574008487, Accuracy: 0.992, client: 0, total: 1000\n",
      "Training client 1\n",
      "Local Epoch 1, Loss: 0.06762130718327689, Accuracy: 0.977, client: 1, total: 1000\n",
      "Local Epoch 2, Loss: 0.0610035588815347, Accuracy: 0.984, client: 1, total: 1000\n",
      "Local Epoch 3, Loss: 0.05521718112655039, Accuracy: 0.988, client: 1, total: 1000\n",
      "Local Epoch 4, Loss: 0.049247740970864415, Accuracy: 0.989, client: 1, total: 1000\n",
      "Local Epoch 5, Loss: 0.04433827574008487, Accuracy: 0.992, client: 1, total: 1000\n",
      "Aggregating 2 local states\n",
      "Round 1, Test Loss: 0.3144674003124237, Test Acc: 0.9211\n",
      "Training client 0\n",
      "Local Epoch 1, Loss: 0.0398021734791207, Accuracy: 0.992, client: 0, total: 1000\n",
      "Local Epoch 2, Loss: 0.03589123798203323, Accuracy: 0.995, client: 0, total: 1000\n",
      "Local Epoch 3, Loss: 0.03219665233544295, Accuracy: 0.996, client: 0, total: 1000\n",
      "Local Epoch 4, Loss: 0.029039923150104792, Accuracy: 0.996, client: 0, total: 1000\n",
      "Local Epoch 5, Loss: 0.02571329699402341, Accuracy: 0.996, client: 0, total: 1000\n",
      "Training client 1\n",
      "Local Epoch 1, Loss: 0.0398021734791207, Accuracy: 0.992, client: 1, total: 1000\n",
      "Local Epoch 2, Loss: 0.03589123798203323, Accuracy: 0.995, client: 1, total: 1000\n",
      "Local Epoch 3, Loss: 0.03219665233544295, Accuracy: 0.996, client: 1, total: 1000\n",
      "Local Epoch 4, Loss: 0.029039923150104792, Accuracy: 0.996, client: 1, total: 1000\n",
      "Local Epoch 5, Loss: 0.02571329699402341, Accuracy: 0.996, client: 1, total: 1000\n",
      "Aggregating 2 local states\n",
      "Round 2, Test Loss: 0.34571948647499084, Test Acc: 0.9202\n",
      "Training client 0\n",
      "Local Epoch 1, Loss: 0.02318034769073509, Accuracy: 0.997, client: 0, total: 1000\n",
      "Local Epoch 2, Loss: 0.020752316791033076, Accuracy: 0.997, client: 0, total: 1000\n",
      "Local Epoch 3, Loss: 0.018359022017013574, Accuracy: 0.997, client: 0, total: 1000\n",
      "Local Epoch 4, Loss: 0.016277087374280633, Accuracy: 0.997, client: 0, total: 1000\n",
      "Local Epoch 5, Loss: 0.01449957004123501, Accuracy: 0.998, client: 0, total: 1000\n",
      "Training client 1\n",
      "Local Epoch 1, Loss: 0.02318034769073509, Accuracy: 0.997, client: 1, total: 1000\n",
      "Local Epoch 2, Loss: 0.020752316791033076, Accuracy: 0.997, client: 1, total: 1000\n",
      "Local Epoch 3, Loss: 0.018359022017013574, Accuracy: 0.997, client: 1, total: 1000\n",
      "Local Epoch 4, Loss: 0.016277087374280633, Accuracy: 0.997, client: 1, total: 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNISTFederatedServer\n\u001b[1;32m      3\u001b[0m server \u001b[38;5;241m=\u001b[39m MNISTFederatedServer(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, model, train, val, test)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/src/models.py:243\u001b[0m, in \u001b[0;36mMNISTFederatedServer.start_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient\u001b[38;5;241m.\u001b[39mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 243\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     local_states\u001b[38;5;241m.\u001b[39mappend(s)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_global_model(local_states)\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/src/models.py:156\u001b[0m, in \u001b[0;36mMNISTFederatedClient.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, labels)\n\u001b[1;32m    158\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/src/models.py:36\u001b[0m, in \u001b[0;36mMNISTConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m---> 36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/.venv/lib/python3.12/site-packages/torch/_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/unipi/CL/project/.venv/lib/python3.12/site-packages/torch/nn/functional.py:796\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 796\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import MNISTFederatedServer\n",
    "\n",
    "server = MNISTFederatedServer(2, 100, 0.001, model, train, val, test)\n",
    "server.start_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
